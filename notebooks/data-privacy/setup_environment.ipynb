{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Data Privacy Demo - Environment Setup\n",
    "\n",
    "This notebook sets up the demo environment. It is called automatically by the main demo notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ENVIRONMENT SETUP\n",
    "# ============================================================================\n",
    "# This notebook is called via %run from the main demo notebook\n",
    "# Configuration is passed from the calling notebook\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "print(\"Setting up demo environment...\")\n",
    "print(f\"→ Mode: {'Temporary tables' if USE_TEMP_TABLES else 'Permanent tables'}\")\n",
    "\n",
    "# Helper function\n",
    "def get_table_type():\n",
    "    return \"TEMPORARY\" if USE_TEMP_TABLES else \"\"\n",
    "\n",
    "# Create schemas (only for permanent tables)\n",
    "if not USE_TEMP_TABLES:\n",
    "    for schema in [HR_SCHEMA, CUSTOMERS_SCHEMA, RETAIL_SCHEMA, GOVERNANCE_SCHEMA]:\n",
    "        spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.{schema}\")\n",
    "    print(\"✓ Schemas created\")\n",
    "\n",
    "# HR employee_info table\n",
    "spark.sql(f\"\"\"CREATE OR REPLACE {get_table_type()} TABLE {CATALOG}.{HR_SCHEMA}.employee_info (\n",
    "    id INT, name STRING, salary DECIMAL(10, 2), ssn STRING)\"\"\")\n",
    "spark.sql(f\"\"\"INSERT INTO {CATALOG}.{HR_SCHEMA}.employee_info VALUES\n",
    "    (1, 'David Wells', 100000.00, '123-45-6789'),\n",
    "    (2, 'Chris Moon', 120000.00, '234-56-7890'),\n",
    "    (3, 'Jane Doe', 95000.00, '345-67-8901'),\n",
    "    (4, 'John Smith', 110000.00, '456-78-9012')\"\"\")\n",
    "\n",
    "# Customers customer_info table\n",
    "spark.sql(f\"\"\"CREATE OR REPLACE {get_table_type()} TABLE {CATALOG}.{CUSTOMERS_SCHEMA}.customer_info (\n",
    "    id INT, email STRING, name STRING, created_at DATE)\"\"\")\n",
    "spark.sql(f\"\"\"INSERT INTO {CATALOG}.{CUSTOMERS_SCHEMA}.customer_info VALUES\n",
    "    (1, 'david.wells@databricks.com', 'David Wells', '2025-01-01'),\n",
    "    (2, 'chris.moon@databricks.com', 'Chris Moon', '2025-02-01'),\n",
    "    (3, 'jane.doe@example.com', 'Jane Doe', '2025-03-15'),\n",
    "    (4, 'john.smith@example.com', 'John Smith', '2025-04-20')\"\"\")\n",
    "\n",
    "# Retail customers table\n",
    "spark.sql(f\"\"\"CREATE OR REPLACE {get_table_type()} TABLE {CATALOG}.{RETAIL_SCHEMA}.customers (\n",
    "    id INT, ssn STRING, name STRING, region STRING)\"\"\")\n",
    "spark.sql(f\"\"\"INSERT INTO {CATALOG}.{RETAIL_SCHEMA}.customers VALUES\n",
    "    (1, '123-45-6789', 'Alice Smith', 'US'),\n",
    "    (2, '234-56-7890', 'Maria Silva', 'EU'),\n",
    "    (3, '456-78-9012', 'Akira Tanaka', 'APAC'),\n",
    "    (4, '567-89-0123', 'Bob Johnson', 'US'),\n",
    "    (5, '678-90-1234', 'Emma Brown', 'EU')\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ Setup Complete!\")\n",
    "print(\"=\"*60)\n",
    "print(\"→ All tables created and populated\")\n",
    "print(\"→ Ready for demonstrations\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
